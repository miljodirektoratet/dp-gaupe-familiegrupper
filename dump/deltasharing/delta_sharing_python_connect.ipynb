{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d7f80da",
   "metadata": {},
   "source": [
    "# Delta Sharing Python Integration\n",
    "\n",
    "This notebook demonstrates how to connect to and use data from a Delta Share using the native Python `delta-sharing` library. This approach provides full functionality and handles advanced Delta features like Deletion Vectors.\n",
    "\n",
    "## Features\n",
    "- ‚úÖ Native Python implementation (no R/Python integration complexity)\n",
    "- ‚úÖ Full Delta Sharing functionality \n",
    "- ‚úÖ Supports Deletion Vectors and advanced Delta features\n",
    "- ‚úÖ Direct data loading without manual file handling\n",
    "- ‚úÖ Built-in authentication and token management"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68960f14",
   "metadata": {},
   "source": [
    "## 1. Install and Import Delta Sharing Libraries\n",
    "\n",
    "First, we'll install the required packages and import the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd93ff4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ delta-sharing already installed\n",
      "üì¶ All libraries imported successfully\n",
      "delta-sharing version: 1.3.3\n",
      "pandas version: 2.3.3\n",
      "Python version: 3.11.13 (main, Jun 12 2025, 12:41:02) [Clang 20.1.4 ]\n"
     ]
    }
   ],
   "source": [
    "# Install delta-sharing if not already installed\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "try:\n",
    "    import delta_sharing\n",
    "    print(\"‚úÖ delta-sharing already installed\")\n",
    "except ImportError:\n",
    "    print(\"Installing delta-sharing...\")\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"delta-sharing>=1.0.0\"])\n",
    "    import delta_sharing\n",
    "    print(\"‚úÖ delta-sharing installed successfully\")\n",
    "\n",
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"üì¶ All libraries imported successfully\")\n",
    "print(f\"delta-sharing version: {delta_sharing.__version__}\")\n",
    "print(f\"pandas version: {pd.__version__}\")\n",
    "print(f\"Python version: {sys.version}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85443557",
   "metadata": {},
   "source": [
    "## 2. Configure Delta Sharing Client\n",
    "\n",
    "Load the configuration file and set up the client connection parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b014d8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Using config file: ../config.share\n",
      "üìÅ File exists: True\n",
      "\n",
      "üìä Configuration details:\n",
      "Endpoint: https://norwayeast.azuredatabricks.net/api/2.0/delta-sharing/metastores/a0334db1-3d6f-43da-9137-ce2562cc9873\n",
      "Credentials version: 1\n",
      "Token expires: 2025-11-12T11:46:45.076Z\n",
      "‚è∞ Hours until expiry: 21.1\n",
      "‚ö†Ô∏è  WARNING: Token expires within 24 hours!\n",
      "\n",
      "‚úÖ Configuration loaded successfully\n"
     ]
    }
   ],
   "source": [
    "# Configuration file path\n",
    "config_path = \"../config.share\"\n",
    "\n",
    "# Check if config file exists\n",
    "if not os.path.exists(config_path):\n",
    "    # Try alternative paths\n",
    "    alternative_paths = [\n",
    "        \"config.share\",\n",
    "        \"/home/rstudio/workspace/config.share\",\n",
    "        \"notebooks/config.share\"\n",
    "    ]\n",
    "    \n",
    "    for path in alternative_paths:\n",
    "        if os.path.exists(path):\n",
    "            config_path = path\n",
    "            break\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"Config file not found. Tried: {[config_path] + alternative_paths}\")\n",
    "\n",
    "print(f\"‚úÖ Using config file: {config_path}\")\n",
    "print(f\"üìÅ File exists: {os.path.exists(config_path)}\")\n",
    "\n",
    "# Load and display configuration (without sensitive data)\n",
    "with open(config_path, 'r') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "print(f\"\\nüìä Configuration details:\")\n",
    "print(f\"Endpoint: {config['endpoint']}\")\n",
    "print(f\"Credentials version: {config['shareCredentialsVersion']}\")\n",
    "print(f\"Token expires: {config['expirationTime']}\")\n",
    "\n",
    "# Check token expiration\n",
    "try:\n",
    "    expiry_time = datetime.fromisoformat(config['expirationTime'].replace('Z', '+00:00'))\n",
    "    time_until_expiry = expiry_time - datetime.now().replace(tzinfo=expiry_time.tzinfo)\n",
    "    hours_remaining = time_until_expiry.total_seconds() / 3600\n",
    "    \n",
    "    print(f\"‚è∞ Hours until expiry: {hours_remaining:.1f}\")\n",
    "    \n",
    "    if hours_remaining < 24:\n",
    "        print(\"‚ö†Ô∏è  WARNING: Token expires within 24 hours!\")\n",
    "    elif hours_remaining < 1:\n",
    "        print(\"üî¥ CRITICAL: Token expires within 1 hour!\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è  Could not parse expiry time: {e}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Configuration loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28cefbc6",
   "metadata": {},
   "source": [
    "## 3. Connect to Delta Sharing Server\n",
    "\n",
    "Create the Delta Sharing client and establish connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4757d10f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Delta Sharing client created successfully\n",
      "Client type: <class 'delta_sharing.delta_sharing.SharingClient'>\n",
      "\n",
      "üîó Testing connection...\n",
      "‚úÖ Connection successful - found 1 share(s)\n"
     ]
    }
   ],
   "source": [
    "# Create Delta Sharing client\n",
    "try:\n",
    "    client = delta_sharing.SharingClient(config_path)\n",
    "    print(\"‚úÖ Delta Sharing client created successfully\")\n",
    "    print(f\"Client type: {type(client)}\")\n",
    "    \n",
    "    # Test connection by trying to list shares\n",
    "    print(\"\\nüîó Testing connection...\")\n",
    "    shares = client.list_shares()\n",
    "    print(f\"‚úÖ Connection successful - found {len(shares)} share(s)\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error creating client: {e}\")\n",
    "    print(\"\\nüõ†Ô∏è  Troubleshooting:\")\n",
    "    print(\"1. Check that config.share file is valid JSON\")\n",
    "    print(\"2. Verify network connectivity to the endpoint\")\n",
    "    print(\"3. Ensure token is not expired\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe127a5",
   "metadata": {},
   "source": [
    "## 4. List Available Shares and Schemas\n",
    "\n",
    "Explore the available shares, schemas, and tables in the Delta Sharing server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06a8b94c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Listing available shares:\n",
      "1. test_delta_share_natur_i_vern\n",
      "\n",
      "‚úÖ Using share: test_delta_share_natur_i_vern\n",
      "\n",
      "üóÇÔ∏è  Schemas in 'test_delta_share_natur_i_vern':\n",
      "1. gold_natur_i_verneomraader\n",
      "\n",
      "‚úÖ Using schema: gold_natur_i_verneomraader\n",
      "\n",
      "üìä Tables in 'gold_natur_i_verneomraader':\n",
      "1. d_variabler (Share: test_delta_share_natur_i_vern, Schema: gold_natur_i_verneomraader)\n",
      "\n",
      "‚úÖ Using table: d_variabler\n",
      "\n",
      "üìù Summary:\n",
      "   Share: test_delta_share_natur_i_vern\n",
      "   Schema: gold_natur_i_verneomraader\n",
      "   Table: d_variabler\n",
      "1. d_variabler (Share: test_delta_share_natur_i_vern, Schema: gold_natur_i_verneomraader)\n",
      "\n",
      "‚úÖ Using table: d_variabler\n",
      "\n",
      "üìù Summary:\n",
      "   Share: test_delta_share_natur_i_vern\n",
      "   Schema: gold_natur_i_verneomraader\n",
      "   Table: d_variabler\n"
     ]
    }
   ],
   "source": [
    "# List all available shares\n",
    "print(\"üîç Listing available shares:\")\n",
    "shares = client.list_shares()\n",
    "\n",
    "for i, share in enumerate(shares, 1):\n",
    "    print(f\"{i}. {share.name}\")\n",
    "\n",
    "# Select first share for exploration\n",
    "if shares:\n",
    "    selected_share_obj = shares[0]  # Keep the Share object\n",
    "    selected_share = selected_share_obj.name  # Extract name for display\n",
    "    print(f\"\\n‚úÖ Using share: {selected_share}\")\n",
    "    \n",
    "    # List schemas in the selected share (pass the Share object, not the name string)\n",
    "    print(f\"\\nüóÇÔ∏è  Schemas in '{selected_share}':\")\n",
    "    schemas = client.list_schemas(selected_share_obj)  # Pass Share object\n",
    "    \n",
    "    for i, schema in enumerate(schemas, 1):\n",
    "        print(f\"{i}. {schema.name}\")\n",
    "    \n",
    "    # Select first schema\n",
    "    if schemas:\n",
    "        selected_schema_obj = schemas[0]  # Keep the Schema object\n",
    "        selected_schema = selected_schema_obj.name  # Extract name for display\n",
    "        print(f\"\\n‚úÖ Using schema: {selected_schema}\")\n",
    "        \n",
    "        # List tables in the selected schema using list_tables method\n",
    "        print(f\"\\nüìä Tables in '{selected_schema}':\")\n",
    "        tables = client.list_tables(selected_schema_obj)  # Pass Schema object\n",
    "        \n",
    "        for i, table in enumerate(tables, 1):\n",
    "            table_name = table.name if hasattr(table, 'name') else str(table)\n",
    "            share_name = table.share if hasattr(table, 'share') else selected_share\n",
    "            schema_name = table.schema if hasattr(table, 'schema') else selected_schema\n",
    "            print(f\"{i}. {table_name} (Share: {share_name}, Schema: {schema_name})\")\n",
    "        \n",
    "        # Store information for next steps\n",
    "        if tables:\n",
    "            selected_table = tables[0].name if hasattr(tables[0], 'name') else str(tables[0])\n",
    "            print(f\"\\n‚úÖ Using table: {selected_table}\")\n",
    "            \n",
    "            # Store variables for later use\n",
    "            share_name = selected_share\n",
    "            schema_name = selected_schema  \n",
    "            table_name = selected_table\n",
    "            \n",
    "            print(f\"\\nüìù Summary:\")\n",
    "            print(f\"   Share: {share_name}\")\n",
    "            print(f\"   Schema: {schema_name}\")\n",
    "            print(f\"   Table: {table_name}\")\n",
    "        else:\n",
    "            print(\"‚ùå No tables found in this schema\")\n",
    "    else:\n",
    "        print(\"‚ùå No schemas found in this share\")\n",
    "else:\n",
    "    print(\"‚ùå No shares available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02512242",
   "metadata": {},
   "source": [
    "## 5. Load Shared Tables as DataFrames\n",
    "\n",
    "Load the Delta table data directly into pandas DataFrames. This approach handles Deletion Vectors automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8be0e994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì• Loading data from table: d_variabler\n",
      "üîó Table URL: ../config.share#test_delta_share_natur_i_vern.gold_natur_i_verneomraader.d_variabler\n",
      "‚è≥ Loading data (this may take a moment)...\n",
      "‚úÖ Data loaded successfully!\n",
      "üìä Dataset shape: 2,087,275 rows √ó 17 columns\n",
      "‚úÖ Data loaded successfully!\n",
      "üìä Dataset shape: 2,087,275 rows √ó 17 columns\n",
      "üíæ Memory usage: 1598.5 MB\n",
      "\n",
      "üìã Data Summary:\n",
      "Column names: ['variabel_key', 'kode_variabeltype_key', 'nin_hovedtypegruppe', 'nin_hovedtype', 'gradient_kode', 'gradient_kode_beskrivelse', 'trinn_ulkm', 'trinn_definisjon', 'trinn_beskrivelse_ulkm', 'gruppe', 'gruppe_beskrivelse', 'tema', 'tema_beskrivelse', 'navn', 'navn_beskrivelse', 'trinn_variabler', 'trinn_beskrivelse_variabler']\n",
      "Data types:\n",
      "  variabel_key: object\n",
      "  kode_variabeltype_key: object\n",
      "  nin_hovedtypegruppe: object\n",
      "  nin_hovedtype: float64\n",
      "  gradient_kode: object\n",
      "  gradient_kode_beskrivelse: object\n",
      "  trinn_ulkm: float64\n",
      "  trinn_definisjon: object\n",
      "  trinn_beskrivelse_ulkm: object\n",
      "  gruppe: object\n",
      "  gruppe_beskrivelse: object\n",
      "  tema: object\n",
      "  tema_beskrivelse: object\n",
      "  navn: object\n",
      "  navn_beskrivelse: object\n",
      "  trinn_variabler: object\n",
      "  trinn_beskrivelse_variabler: object\n",
      "\n",
      "üîç Last 5 rows:\n",
      "üíæ Memory usage: 1598.5 MB\n",
      "\n",
      "üìã Data Summary:\n",
      "Column names: ['variabel_key', 'kode_variabeltype_key', 'nin_hovedtypegruppe', 'nin_hovedtype', 'gradient_kode', 'gradient_kode_beskrivelse', 'trinn_ulkm', 'trinn_definisjon', 'trinn_beskrivelse_ulkm', 'gruppe', 'gruppe_beskrivelse', 'tema', 'tema_beskrivelse', 'navn', 'navn_beskrivelse', 'trinn_variabler', 'trinn_beskrivelse_variabler']\n",
      "Data types:\n",
      "  variabel_key: object\n",
      "  kode_variabeltype_key: object\n",
      "  nin_hovedtypegruppe: object\n",
      "  nin_hovedtype: float64\n",
      "  gradient_kode: object\n",
      "  gradient_kode_beskrivelse: object\n",
      "  trinn_ulkm: float64\n",
      "  trinn_definisjon: object\n",
      "  trinn_beskrivelse_ulkm: object\n",
      "  gruppe: object\n",
      "  gruppe_beskrivelse: object\n",
      "  tema: object\n",
      "  tema_beskrivelse: object\n",
      "  navn: object\n",
      "  navn_beskrivelse: object\n",
      "  trinn_variabler: object\n",
      "  trinn_beskrivelse_variabler: object\n",
      "\n",
      "üîç Last 5 rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variabel_key</th>\n",
       "      <th>kode_variabeltype_key</th>\n",
       "      <th>nin_hovedtypegruppe</th>\n",
       "      <th>nin_hovedtype</th>\n",
       "      <th>gradient_kode</th>\n",
       "      <th>gradient_kode_beskrivelse</th>\n",
       "      <th>trinn_ulkm</th>\n",
       "      <th>trinn_definisjon</th>\n",
       "      <th>trinn_beskrivelse_ulkm</th>\n",
       "      <th>gruppe</th>\n",
       "      <th>gruppe_beskrivelse</th>\n",
       "      <th>tema</th>\n",
       "      <th>tema_beskrivelse</th>\n",
       "      <th>navn</th>\n",
       "      <th>navn_beskrivelse</th>\n",
       "      <th>trinn_variabler</th>\n",
       "      <th>trinn_beskrivelse_variabler</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2087270</th>\n",
       "      <td>FFFE3360-A7A3-4E46-ABC2-4C8F94B6AB18</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>7</td>\n",
       "      <td>Tilstandsvariasjon</td>\n",
       "      <td>FA</td>\n",
       "      <td>Fremmedartsinnslag</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>Uten fremmedarter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2087271</th>\n",
       "      <td>FFFE7A10-9E22-42CB-B1E3-888F1F7EF639</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>7</td>\n",
       "      <td>Tilstandsvariasjon</td>\n",
       "      <td>FA</td>\n",
       "      <td>Fremmedartsinnslag</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>Uten fremmedarter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2087272</th>\n",
       "      <td>FFFF2FA0-7E3A-4CCF-947D-2992853CD39E</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>5</td>\n",
       "      <td>Menneskeskapte objekter</td>\n",
       "      <td>XG</td>\n",
       "      <td>Annen l√∏s gjenstand</td>\n",
       "      <td>SM</td>\n",
       "      <td>Sm√• objekter</td>\n",
       "      <td>1</td>\n",
       "      <td>0 ‚Äì 1/16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2087273</th>\n",
       "      <td>FFFF60BD-BD5C-4088-BC1B-82B2E924FCA6</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>7</td>\n",
       "      <td>Tilstandsvariasjon</td>\n",
       "      <td>FA</td>\n",
       "      <td>Fremmedartsinnslag</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>Uten fremmedarter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2087274</th>\n",
       "      <td>FFFF7803-9D16-4711-860E-FCB3CFB35497</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>7</td>\n",
       "      <td>Tilstandsvariasjon</td>\n",
       "      <td>JB</td>\n",
       "      <td>Jord-bruk (aktuell bruk av jord)</td>\n",
       "      <td>BA</td>\n",
       "      <td>Aktuell bruksintensitet</td>\n",
       "      <td>1</td>\n",
       "      <td>ikke i bruk</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 variabel_key kode_variabeltype_key  \\\n",
       "2087270  FFFE3360-A7A3-4E46-ABC2-4C8F94B6AB18                     0   \n",
       "2087271  FFFE7A10-9E22-42CB-B1E3-888F1F7EF639                     0   \n",
       "2087272  FFFF2FA0-7E3A-4CCF-947D-2992853CD39E                     0   \n",
       "2087273  FFFF60BD-BD5C-4088-BC1B-82B2E924FCA6                     0   \n",
       "2087274  FFFF7803-9D16-4711-860E-FCB3CFB35497                     0   \n",
       "\n",
       "        nin_hovedtypegruppe  nin_hovedtype gradient_kode  \\\n",
       "2087270                None            NaN          None   \n",
       "2087271                None            NaN          None   \n",
       "2087272                None            NaN          None   \n",
       "2087273                None            NaN          None   \n",
       "2087274                None            NaN          None   \n",
       "\n",
       "        gradient_kode_beskrivelse  trinn_ulkm trinn_definisjon  \\\n",
       "2087270                      None         NaN             None   \n",
       "2087271                      None         NaN             None   \n",
       "2087272                      None         NaN             None   \n",
       "2087273                      None         NaN             None   \n",
       "2087274                      None         NaN             None   \n",
       "\n",
       "        trinn_beskrivelse_ulkm gruppe       gruppe_beskrivelse tema  \\\n",
       "2087270                   None      7       Tilstandsvariasjon   FA   \n",
       "2087271                   None      7       Tilstandsvariasjon   FA   \n",
       "2087272                   None      5  Menneskeskapte objekter   XG   \n",
       "2087273                   None      7       Tilstandsvariasjon   FA   \n",
       "2087274                   None      7       Tilstandsvariasjon   JB   \n",
       "\n",
       "                         tema_beskrivelse  navn         navn_beskrivelse  \\\n",
       "2087270                Fremmedartsinnslag  None                     None   \n",
       "2087271                Fremmedartsinnslag  None                     None   \n",
       "2087272               Annen l√∏s gjenstand    SM            Sm√• objekter    \n",
       "2087273                Fremmedartsinnslag  None                     None   \n",
       "2087274  Jord-bruk (aktuell bruk av jord)    BA  Aktuell bruksintensitet   \n",
       "\n",
       "        trinn_variabler trinn_beskrivelse_variabler  \n",
       "2087270               0           Uten fremmedarter  \n",
       "2087271               0           Uten fremmedarter  \n",
       "2087272               1                    0 ‚Äì 1/16  \n",
       "2087273               0           Uten fremmedarter  \n",
       "2087274               1                 ikke i bruk  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìà Basic statistics:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nin_hovedtype</th>\n",
       "      <th>trinn_ulkm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>257546.000000</td>\n",
       "      <td>257546.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>9.242601</td>\n",
       "      <td>1.303689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>11.145309</td>\n",
       "      <td>0.626470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>45.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       nin_hovedtype     trinn_ulkm\n",
       "count  257546.000000  257546.000000\n",
       "mean        9.242601       1.303689\n",
       "std        11.145309       0.626470\n",
       "min         1.000000       1.000000\n",
       "25%         4.000000       1.000000\n",
       "50%         4.000000       1.000000\n",
       "75%         4.000000       1.000000\n",
       "max        45.000000       6.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load data from the Delta table\n",
    "if 'table_name' in locals():\n",
    "    print(f\"üì• Loading data from table: {table_name}\")\n",
    "    \n",
    "    # Method 1: Using the config file with table reference\n",
    "    try:\n",
    "        # Format: config_file#share.schema.table\n",
    "        table_url = f\"{config_path}#{share_name}.{schema_name}.{table_name}\"\n",
    "        print(f\"üîó Table URL: {table_url}\")\n",
    "        \n",
    "        print(\"‚è≥ Loading data (this may take a moment)...\")\n",
    "        df = delta_sharing.load_as_pandas(table_url)\n",
    "        \n",
    "        print(f\"‚úÖ Data loaded successfully!\")\n",
    "        print(f\"üìä Dataset shape: {df.shape[0]:,} rows √ó {df.shape[1]} columns\")\n",
    "        print(f\"üíæ Memory usage: {df.memory_usage(deep=True).sum() / 1024**2:.1f} MB\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Method 1 failed: {e}\")\n",
    "        \n",
    "        # Method 2: Using client and table reference\n",
    "        try:\n",
    "            print(\"\\nüîÑ Trying alternative method with client...\")\n",
    "            \n",
    "            # Create table reference\n",
    "            table_ref = delta_sharing.Table(name=table_name, share=share_name, schema=schema_name)\n",
    "            df = delta_sharing.load_as_pandas(table_ref, client)\n",
    "            \n",
    "            print(f\"‚úÖ Data loaded successfully with method 2!\")\n",
    "            print(f\"üìä Dataset shape: {df.shape[0]:,} rows √ó {df.shape[1]} columns\")\n",
    "            \n",
    "        except Exception as e2:\n",
    "            print(f\"‚ùå Method 2 also failed: {e2}\")\n",
    "            print(f\"\\nüõ†Ô∏è  Troubleshooting tips:\")\n",
    "            print(f\"1. Verify the table name: {table_name}\")\n",
    "            print(f\"2. Check share access permissions\")\n",
    "            print(f\"3. Ensure network connectivity\")\n",
    "            df = None\n",
    "    \n",
    "    # Display basic information about the loaded data\n",
    "    if 'df' in locals() and df is not None:\n",
    "        print(f\"\\nüìã Data Summary:\")\n",
    "        print(f\"Column names: {list(df.columns)}\")\n",
    "        print(f\"Data types:\")\n",
    "        for col, dtype in df.dtypes.items():\n",
    "            print(f\"  {col}: {dtype}\")\n",
    "        \n",
    "        print(f\"\\nüîç Last 5 rows:\")\n",
    "        display(df.tail())\n",
    "        \n",
    "        print(f\"\\nüìà Basic statistics:\")\n",
    "        display(df.describe())\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå No table selected. Please run the previous cell to select a table.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e076c07",
   "metadata": {},
   "source": [
    "## 6. Query and Manipulate Shared Data\n",
    "\n",
    "Perform data operations, filtering, and analysis on the loaded Delta table data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0545eea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data exploration and manipulation\n",
    "if 'df' in locals() and df is not None:\n",
    "    print(\"üî¨ Data Exploration and Analysis\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # 1. Basic data quality checks\n",
    "    print(f\"\\n1Ô∏è‚É£ Data Quality Overview:\")\n",
    "    print(f\"   Total rows: {len(df):,}\")\n",
    "    print(f\"   Total columns: {len(df.columns)}\")\n",
    "    print(f\"   Missing values: {df.isnull().sum().sum():,}\")\n",
    "    print(f\"   Duplicate rows: {df.duplicated().sum():,}\")\n",
    "    \n",
    "    # 2. Missing values per column\n",
    "    missing_data = df.isnull().sum()\n",
    "    if missing_data.sum() > 0:\n",
    "        print(f\"\\nüîç Missing values by column:\")\n",
    "        missing_cols = missing_data[missing_data > 0].sort_values(ascending=False)\n",
    "        for col, count in missing_cols.items():\n",
    "            pct = (count / len(df)) * 100\n",
    "            print(f\"   {col}: {count:,} ({pct:.1f}%)\")\n",
    "    else:\n",
    "        print(f\"\\n‚úÖ No missing values found!\")\n",
    "    \n",
    "    # 3. Data types and memory usage\n",
    "    print(f\"\\nüìä Memory usage by column:\")\n",
    "    memory_usage = df.memory_usage(deep=True)\n",
    "    for col, usage in memory_usage.items():\n",
    "        print(f\"   {col}: {usage / 1024**2:.2f} MB\")\n",
    "    \n",
    "    # 4. Numeric columns analysis\n",
    "    numeric_cols = df.select_dtypes(include=['number']).columns\n",
    "    if len(numeric_cols) > 0:\n",
    "        print(f\"\\nüìà Numeric columns summary:\")\n",
    "        display(df[numeric_cols].describe())\n",
    "        \n",
    "        # Show correlations if multiple numeric columns\n",
    "        if len(numeric_cols) > 1:\n",
    "            print(f\"\\nüîó Correlations between numeric columns:\")\n",
    "            corr_matrix = df[numeric_cols].corr()\n",
    "            display(corr_matrix)\n",
    "    \n",
    "    # 5. Categorical columns analysis  \n",
    "    categorical_cols = df.select_dtypes(include=['object', 'category']).columns\n",
    "    if len(categorical_cols) > 0:\n",
    "        print(f\"\\nüìù Categorical columns analysis:\")\n",
    "        for col in categorical_cols[:5]:  # Show first 5 categorical columns\n",
    "            unique_count = df[col].nunique()\n",
    "            print(f\"\\n   Column: {col}\")\n",
    "            print(f\"   Unique values: {unique_count}\")\n",
    "            if unique_count <= 10:\n",
    "                value_counts = df[col].value_counts()\n",
    "                print(f\"   Value distribution:\")\n",
    "                for value, count in value_counts.head().items():\n",
    "                    pct = (count / len(df)) * 100\n",
    "                    print(f\"     {value}: {count:,} ({pct:.1f}%)\")\n",
    "    \n",
    "    # 6. Create some sample visualizations\n",
    "    print(f\"\\nüìä Sample Data Visualizations:\")\n",
    "    \n",
    "    # Import visualization libraries\n",
    "    try:\n",
    "        import matplotlib.pyplot as plt\n",
    "        import seaborn as sns\n",
    "        \n",
    "        plt.style.use('default')\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "        fig.suptitle(f'Data Analysis: {table_name}', fontsize=16)\n",
    "        \n",
    "        # Plot 1: Missing values heatmap (if any missing data)\n",
    "        if df.isnull().sum().sum() > 0:\n",
    "            sns.heatmap(df.isnull(), ax=axes[0,0], cbar=True, yticklabels=False)\n",
    "            axes[0,0].set_title('Missing Values Pattern')\n",
    "        else:\n",
    "            axes[0,0].text(0.5, 0.5, 'No Missing Values', ha='center', va='center')\n",
    "            axes[0,0].set_title('Missing Values Status')\n",
    "        \n",
    "        # Plot 2: Data types distribution\n",
    "        dtype_counts = df.dtypes.value_counts()\n",
    "        axes[0,1].pie(dtype_counts.values, labels=dtype_counts.index, autopct='%1.1f%%')\n",
    "        axes[0,1].set_title('Data Types Distribution')\n",
    "        \n",
    "        # Plot 3: Numeric column histogram (first numeric column)\n",
    "        if len(numeric_cols) > 0:\n",
    "            col = numeric_cols[0]\n",
    "            df[col].hist(bins=30, ax=axes[1,0])\n",
    "            axes[1,0].set_title(f'Distribution: {col}')\n",
    "            axes[1,0].set_xlabel(col)\n",
    "            axes[1,0].set_ylabel('Frequency')\n",
    "        else:\n",
    "            axes[1,0].text(0.5, 0.5, 'No Numeric Columns', ha='center', va='center')\n",
    "            axes[1,0].set_title('Numeric Data')\n",
    "        \n",
    "        # Plot 4: Categorical column bar chart (first categorical column)\n",
    "        if len(categorical_cols) > 0:\n",
    "            col = categorical_cols[0]\n",
    "            top_values = df[col].value_counts().head(10)\n",
    "            top_values.plot(kind='bar', ax=axes[1,1])\n",
    "            axes[1,1].set_title(f'Top Values: {col}')\n",
    "            axes[1,1].tick_params(axis='x', rotation=45)\n",
    "        else:\n",
    "            axes[1,1].text(0.5, 0.5, 'No Categorical Columns', ha='center', va='center')\n",
    "            axes[1,1].set_title('Categorical Data')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "    except ImportError:\n",
    "        print(\"üìä Matplotlib/Seaborn not available. Install with: pip install matplotlib seaborn\")\n",
    "    \n",
    "    print(f\"\\n‚úÖ Data exploration completed!\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå No data available for analysis. Please load data first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f886e078",
   "metadata": {},
   "source": [
    "### Advanced Querying\n",
    "\n",
    "Demonstrate advanced querying capabilities with filters and limits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc51141f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced querying with delta-sharing\n",
    "if 'table_url' in locals():\n",
    "    print(\"üîç Advanced Querying Examples\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # Example 1: Load with limit\n",
    "    print(f\"\\n1Ô∏è‚É£ Loading first 100 rows only:\")\n",
    "    try:\n",
    "        df_limited = delta_sharing.load_as_pandas(table_url, limit=100)\n",
    "        print(f\"   ‚úÖ Loaded {len(df_limited):,} rows\")\n",
    "        print(f\"   Columns: {list(df_limited.columns)}\")\n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå Limit query failed: {e}\")\n",
    "    \n",
    "    # Example 2: Load with predicates (filtering)\n",
    "    print(f\"\\n2Ô∏è‚É£ Loading with predicates (if supported):\")\n",
    "    \n",
    "    # Note: Predicates depend on the specific table schema\n",
    "    # Here are some common examples you can adapt:\n",
    "    \n",
    "    sample_predicates = [\n",
    "        # \"column_name > 100\",\n",
    "        # \"status = 'ACTIVE'\",\n",
    "        # \"date >= '2023-01-01'\",\n",
    "    ]\n",
    "    \n",
    "    if sample_predicates:\n",
    "        for predicate in sample_predicates:\n",
    "            try:\n",
    "                print(f\"   Trying predicate: {predicate}\")\n",
    "                df_filtered = delta_sharing.load_as_pandas(\n",
    "                    table_url, \n",
    "                    predicates=[predicate]\n",
    "                )\n",
    "                print(f\"   ‚úÖ Filtered data: {len(df_filtered):,} rows\")\n",
    "                break\n",
    "            except Exception as e:\n",
    "                print(f\"   ‚ùå Predicate '{predicate}' failed: {e}\")\n",
    "    else:\n",
    "        print(\"   ‚ÑπÔ∏è  No predicates defined. Add column-specific filters above.\")\n",
    "    \n",
    "    # Example 3: Load specific version (if versioning is supported)\n",
    "    print(f\"\\n3Ô∏è‚É£ Loading specific table version:\")\n",
    "    try:\n",
    "        # Most recent version (version=0 means latest)\n",
    "        df_version = delta_sharing.load_as_pandas(table_url, version=0)\n",
    "        print(f\"   ‚úÖ Latest version loaded: {len(df_version):,} rows\")\n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå Version loading failed: {e}\")\n",
    "        print(\"   ‚ÑπÔ∏è  Version support may not be available for this table\")\n",
    "    \n",
    "    # Example 4: Using pandas for post-processing\n",
    "    if 'df' in locals() and df is not None:\n",
    "        print(f\"\\n4Ô∏è‚É£ Post-processing with pandas:\")\n",
    "        \n",
    "        # Basic filtering\n",
    "        non_null_rows = len(df.dropna())\n",
    "        print(f\"   Rows without missing values: {non_null_rows:,}\")\n",
    "        \n",
    "        # Column-specific operations\n",
    "        numeric_cols = df.select_dtypes(include=['number']).columns\n",
    "        if len(numeric_cols) > 0:\n",
    "            col = numeric_cols[0]\n",
    "            print(f\"   Statistics for '{col}':\")\n",
    "            print(f\"     Mean: {df[col].mean():.2f}\")\n",
    "            print(f\"     Median: {df[col].median():.2f}\")\n",
    "            print(f\"     Min: {df[col].min():.2f}\")\n",
    "            print(f\"     Max: {df[col].max():.2f}\")\n",
    "        \n",
    "        # Grouping operations\n",
    "        categorical_cols = df.select_dtypes(include=['object', 'category']).columns\n",
    "        if len(categorical_cols) > 0 and len(numeric_cols) > 0:\n",
    "            cat_col = categorical_cols[0]\n",
    "            num_col = numeric_cols[0]\n",
    "            try:\n",
    "                grouped = df.groupby(cat_col)[num_col].agg(['count', 'mean', 'std'])\n",
    "                print(f\"\\n   Grouped statistics ({cat_col} vs {num_col}):\")\n",
    "                display(grouped.head())\n",
    "            except Exception as e:\n",
    "                print(f\"   ‚ùå Grouping failed: {e}\")\n",
    "    \n",
    "    print(f\"\\n‚úÖ Advanced querying examples completed!\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ùå No table URL available. Please load a table first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94a6742",
   "metadata": {},
   "source": [
    "## 7. Handle Authentication and Security\n",
    "\n",
    "Best practices for authentication, token management, and secure connections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedc0966",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authentication and Security Best Practices\n",
    "print(\"üîê Authentication and Security Status\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "# 1. Check token expiration status\n",
    "if 'config' in locals():\n",
    "    print(f\"\\n1Ô∏è‚É£ Token Status:\")\n",
    "    try:\n",
    "        expiry_time = datetime.fromisoformat(config['expirationTime'].replace('Z', '+00:00'))\n",
    "        current_time = datetime.now().replace(tzinfo=expiry_time.tzinfo)\n",
    "        time_remaining = expiry_time - current_time\n",
    "        \n",
    "        hours_remaining = time_remaining.total_seconds() / 3600\n",
    "        days_remaining = time_remaining.days\n",
    "        \n",
    "        print(f\"   Expires: {expiry_time.strftime('%Y-%m-%d %H:%M:%S %Z')}\")\n",
    "        print(f\"   Time remaining: {days_remaining} days, {hours_remaining % 24:.1f} hours\")\n",
    "        \n",
    "        # Security alerts\n",
    "        if hours_remaining < 1:\n",
    "            print(\"   üî¥ CRITICAL: Token expires within 1 hour!\")\n",
    "        elif hours_remaining < 24:\n",
    "            print(\"   üü° WARNING: Token expires within 24 hours\")\n",
    "        elif days_remaining < 7:\n",
    "            print(\"   üü† NOTICE: Token expires within 1 week\")\n",
    "        else:\n",
    "            print(\"   ‚úÖ Token is valid for more than a week\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå Could not parse token expiration: {e}\")\n",
    "\n",
    "# 2. Connection security information\n",
    "print(f\"\\n2Ô∏è‚É£ Connection Security:\")\n",
    "endpoint = config.get('endpoint', 'Unknown')\n",
    "print(f\"   Endpoint: {endpoint}\")\n",
    "\n",
    "if endpoint.startswith('https://'):\n",
    "    print(\"   ‚úÖ Secure HTTPS connection\")\n",
    "else:\n",
    "    print(\"   ‚ö†Ô∏è  Warning: Non-HTTPS endpoint detected\")\n",
    "\n",
    "# Bearer token security (don't expose the actual token)\n",
    "bearer_token = config.get('bearerToken', '')\n",
    "if bearer_token:\n",
    "    print(f\"   ‚úÖ Bearer token present ({len(bearer_token)} characters)\")\n",
    "    # Check token format\n",
    "    if bearer_token.startswith('dapi'):\n",
    "        print(\"   ‚úÖ Databricks API token format detected\")\n",
    "    else:\n",
    "        print(\"   ‚ÑπÔ∏è  Custom token format\")\n",
    "else:\n",
    "    print(\"   ‚ùå No bearer token found!\")\n",
    "\n",
    "# 3. Best practices checklist\n",
    "print(f\"\\n3Ô∏è‚É£ Security Best Practices Checklist:\")\n",
    "practices = [\n",
    "    (\"Store config files securely\", \"‚úÖ\" if os.path.exists(config_path) else \"‚ùå\"),\n",
    "    (\"Use environment variables for secrets\", \"‚ÑπÔ∏è\"),\n",
    "    (\"Regularly rotate access tokens\", \"‚ÑπÔ∏è\"),\n",
    "    (\"Monitor token expiration\", \"‚úÖ\" if hours_remaining > 24 else \"‚ö†Ô∏è\"),\n",
    "    (\"Use HTTPS connections only\", \"‚úÖ\" if endpoint.startswith('https://') else \"‚ùå\"),\n",
    "    (\"Limit token scope/permissions\", \"‚ÑπÔ∏è\"),\n",
    "    (\"Audit data access logs\", \"‚ÑπÔ∏è\")\n",
    "]\n",
    "\n",
    "for practice, status in practices:\n",
    "    print(f\"   {status} {practice}\")\n",
    "\n",
    "# 4. Token refresh guidance\n",
    "print(f\"\\n4Ô∏è‚É£ Token Refresh Guidance:\")\n",
    "print(\"   When your token approaches expiration:\")\n",
    "print(\"   1. Contact your data provider for a new token\")\n",
    "print(\"   2. Update the config.share file with new credentials\")\n",
    "print(\"   3. Test the connection with the new token\")\n",
    "print(\"   4. Consider automating token renewal if possible\")\n",
    "\n",
    "# 5. Environment setup for production\n",
    "print(f\"\\n5Ô∏è‚É£ Production Environment Setup:\")\n",
    "print(\"   For production use, consider:\")\n",
    "print(\"   1. Use environment variables instead of config files:\")\n",
    "print(\"      export DELTA_SHARING_ENDPOINT='...'\")\n",
    "print(\"      export DELTA_SHARING_TOKEN='...'\")\n",
    "print(\"   2. Implement automatic token refresh\")\n",
    "print(\"   3. Set up monitoring for failed connections\")\n",
    "print(\"   4. Use secrets management systems (AWS Secrets Manager, etc.)\")\n",
    "print(\"   5. Implement retry logic with exponential backoff\")\n",
    "\n",
    "# 6. Security monitoring\n",
    "print(f\"\\n6Ô∏è‚É£ Security Monitoring:\")\n",
    "if 'client' in locals():\n",
    "    try:\n",
    "        # Test connection health\n",
    "        test_shares = client.list_shares()\n",
    "        print(f\"   ‚úÖ Connection health check passed\")\n",
    "        print(f\"   üìä Accessible shares: {len(test_shares)}\")\n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå Connection health check failed: {e}\")\n",
    "        print(f\"   üõ†Ô∏è  This may indicate token expiration or network issues\")\n",
    "\n",
    "print(f\"\\n‚úÖ Security assessment completed!\")\n",
    "\n",
    "# Example of secure environment variable usage\n",
    "print(f\"\\nüí° Example: Using environment variables\")\n",
    "print(\"\"\"\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Create config from environment variables\n",
    "def create_config_from_env():\n",
    "    return {\n",
    "        \"shareCredentialsVersion\": 1,\n",
    "        \"endpoint\": os.environ.get(\"DELTA_SHARING_ENDPOINT\"),\n",
    "        \"bearerToken\": os.environ.get(\"DELTA_SHARING_TOKEN\"),\n",
    "        \"expirationTime\": os.environ.get(\"DELTA_SHARING_EXPIRY\")\n",
    "    }\n",
    "\n",
    "# Usage:\n",
    "# config = create_config_from_env()\n",
    "# client = delta_sharing.SharingClient(config)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98128c2f",
   "metadata": {},
   "source": [
    "## 8. Save and Export Data\n",
    "\n",
    "Save the loaded data in various formats for further analysis and sharing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba4491d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Saving and Exporting Data\n",
      "===================================\n",
      "üìÅ Output directory: data/delta-share-downloads\n",
      "\n",
      "üìä Dataset info:\n",
      "   Table: d_variabler\n",
      "   Rows: 2,087,275\n",
      "   Columns: 17\n",
      "   Size: 1598.5 MB\n",
      "   Size: 1598.5 MB\n",
      "\n",
      "‚úÖ Saved as Parquet: data/delta-share-downloads/d_variabler_20251111_144720.parquet (81.2 MB)\n",
      "\n",
      "‚úÖ Saved as Parquet: data/delta-share-downloads/d_variabler_20251111_144720.parquet (81.2 MB)\n",
      "‚úÖ Saved as CSV: data/delta-share-downloads/d_variabler_20251111_144720.csv (263.8 MB)\n",
      "‚ö†Ô∏è  Skipping Excel export (dataset too large: 2,087,275 rows)\n",
      "‚úÖ Saved as CSV: data/delta-share-downloads/d_variabler_20251111_144720.csv (263.8 MB)\n",
      "‚ö†Ô∏è  Skipping Excel export (dataset too large: 2,087,275 rows)\n",
      "‚ùå Metadata save failed: Object of type bool is not JSON serializable\n",
      "‚ùå Metadata save failed: Object of type bool is not JSON serializable\n",
      "‚úÖ Saved summary report: data/delta-share-downloads/d_variabler_20251111_144720_summary.txt\n",
      "\\nüéâ Data export completed!\n",
      "üìÅ All files saved to: /home/wilaca/git/miljodir/dp-gaupe-familiegrupper/notebooks/data/delta-share-downloads\n",
      "\\nüìÑ Created files:\n",
      "   d_variabler_20251111_144720.csv (263.8 MB)\n",
      "   d_variabler_20251111_144720.parquet (81.2 MB)\n",
      "   d_variabler_20251111_144720_metadata.json (0.0 MB)\n",
      "   d_variabler_20251111_144720_summary.txt (0.0 MB)\n",
      "‚úÖ Saved summary report: data/delta-share-downloads/d_variabler_20251111_144720_summary.txt\n",
      "\\nüéâ Data export completed!\n",
      "üìÅ All files saved to: /home/wilaca/git/miljodir/dp-gaupe-familiegrupper/notebooks/data/delta-share-downloads\n",
      "\\nüìÑ Created files:\n",
      "   d_variabler_20251111_144720.csv (263.8 MB)\n",
      "   d_variabler_20251111_144720.parquet (81.2 MB)\n",
      "   d_variabler_20251111_144720_metadata.json (0.0 MB)\n",
      "   d_variabler_20251111_144720_summary.txt (0.0 MB)\n"
     ]
    }
   ],
   "source": [
    "# Save and export the loaded data\n",
    "if 'df' in locals() and df is not None:\n",
    "    print(\"üíæ Saving and Exporting Data\")\n",
    "    print(\"=\" * 35)\n",
    "    \n",
    "    # Create output directory\n",
    "    output_dir = \"data/delta-share-downloads\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    print(f\"üìÅ Output directory: {output_dir}\")\n",
    "    \n",
    "    # Generate filename with timestamp\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    base_filename = f\"{table_name}_{timestamp}\"\n",
    "    \n",
    "    print(f\"\\nüìä Dataset info:\")\n",
    "    print(f\"   Table: {table_name}\")\n",
    "    print(f\"   Rows: {len(df):,}\")\n",
    "    print(f\"   Columns: {len(df.columns)}\")\n",
    "    print(f\"   Size: {df.memory_usage(deep=True).sum() / 1024**2:.1f} MB\")\n",
    "    \n",
    "    # 1. Save as Parquet (recommended for large datasets)\n",
    "    try:\n",
    "        parquet_file = os.path.join(output_dir, f\"{base_filename}.parquet\")\n",
    "        df.to_parquet(parquet_file, index=False)\n",
    "        file_size = os.path.getsize(parquet_file) / 1024**2\n",
    "        print(f\"\\n‚úÖ Saved as Parquet: {parquet_file} ({file_size:.1f} MB)\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Parquet save failed: {e}\")\n",
    "    \n",
    "    # 2. Save as CSV (for compatibility)\n",
    "    try:\n",
    "        csv_file = os.path.join(output_dir, f\"{base_filename}.csv\")\n",
    "        df.to_csv(csv_file, index=False)\n",
    "        file_size = os.path.getsize(csv_file) / 1024**2\n",
    "        print(f\"‚úÖ Saved as CSV: {csv_file} ({file_size:.1f} MB)\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå CSV save failed: {e}\")\n",
    "    \n",
    "    # 3. Save as Excel (for small to medium datasets)\n",
    "    if len(df) <= 50000:  # Excel row limit consideration\n",
    "        try:\n",
    "            excel_file = os.path.join(output_dir, f\"{base_filename}.xlsx\")\n",
    "            df.to_excel(excel_file, index=False, engine='openpyxl')\n",
    "            file_size = os.path.getsize(excel_file) / 1024**2\n",
    "            print(f\"‚úÖ Saved as Excel: {excel_file} ({file_size:.1f} MB)\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Excel save failed (install openpyxl if needed): {e}\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è  Skipping Excel export (dataset too large: {len(df):,} rows)\")\n",
    "    \n",
    "    # 4. Save metadata as JSON\n",
    "    try:\n",
    "        metadata = {\n",
    "            \"table_name\": table_name,\n",
    "            \"share_name\": share_name,\n",
    "            \"schema_name\": schema_name,\n",
    "            \"export_timestamp\": datetime.now().isoformat(),\n",
    "            \"row_count\": len(df),\n",
    "            \"column_count\": len(df.columns),\n",
    "            \"columns\": list(df.columns),\n",
    "            \"dtypes\": {col: str(dtype) for col, dtype in df.dtypes.items()},\n",
    "            \"memory_usage_mb\": df.memory_usage(deep=True).sum() / 1024**2,\n",
    "            \"has_missing_values\": df.isnull().any().any(),\n",
    "            \"missing_value_count\": int(df.isnull().sum().sum())\n",
    "        }\n",
    "        \n",
    "        metadata_file = os.path.join(output_dir, f\"{base_filename}_metadata.json\")\n",
    "        with open(metadata_file, 'w') as f:\n",
    "            json.dump(metadata, f, indent=2)\n",
    "        print(f\"‚úÖ Saved metadata: {metadata_file}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Metadata save failed: {e}\")\n",
    "    \n",
    "    # 5. Check for spatial data and save as GeoParquet if applicable\n",
    "    potential_geom_cols = [col for col in df.columns \n",
    "                          if any(geo_word in col.lower() \n",
    "                                for geo_word in ['geom', 'geometry', 'shape', 'wkt', 'wkb'])]\n",
    "    \n",
    "    if potential_geom_cols:\n",
    "        print(f\"\\nüó∫Ô∏è  Potential geometry columns detected: {potential_geom_cols}\")\n",
    "        try:\n",
    "            import geopandas as gpd\n",
    "            \n",
    "            # Try to convert to GeoDataFrame\n",
    "            for geom_col in potential_geom_cols:\n",
    "                try:\n",
    "                    # Attempt to create geometry from various formats\n",
    "                    if df[geom_col].dtype == 'object':\n",
    "                        from shapely import wkt\n",
    "                        gdf = gpd.GeoDataFrame(df, geometry=gpd.GeoSeries.from_wkt(df[geom_col]))\n",
    "                        \n",
    "                        geoparquet_file = os.path.join(output_dir, f\"{base_filename}.geoparquet\")\n",
    "                        gdf.to_parquet(geoparquet_file)\n",
    "                        file_size = os.path.getsize(geoparquet_file) / 1024**2\n",
    "                        print(f\"‚úÖ Saved as GeoParquet: {geoparquet_file} ({file_size:.1f} MB)\")\n",
    "                        break\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    print(f\"   ‚ùå Could not process {geom_col} as geometry: {e}\")\n",
    "                    \n",
    "        except ImportError:\n",
    "            print(f\"   ‚ÑπÔ∏è  Install geopandas for spatial data support: pip install geopandas\")\n",
    "    \n",
    "    # 6. Create a summary report\n",
    "    try:\n",
    "        summary_file = os.path.join(output_dir, f\"{base_filename}_summary.txt\")\n",
    "        with open(summary_file, 'w') as f:\n",
    "            f.write(f\"Delta Sharing Data Export Summary\\\\n\")\n",
    "            f.write(f\"================================\\\\n\\\\n\")\n",
    "            f.write(f\"Export Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\\\n\")\n",
    "            f.write(f\"Table: {table_name}\\\\n\")\n",
    "            f.write(f\"Share: {share_name}\\\\n\")\n",
    "            f.write(f\"Schema: {schema_name}\\\\n\\\\n\")\n",
    "            f.write(f\"Dataset Statistics:\\\\n\")\n",
    "            f.write(f\"- Rows: {len(df):,}\\\\n\")\n",
    "            f.write(f\"- Columns: {len(df.columns)}\\\\n\")\n",
    "            f.write(f\"- Memory Usage: {df.memory_usage(deep=True).sum() / 1024**2:.1f} MB\\\\n\")\n",
    "            f.write(f\"- Missing Values: {df.isnull().sum().sum():,}\\\\n\\\\n\")\n",
    "            f.write(f\"Columns:\\\\n\")\n",
    "            for i, (col, dtype) in enumerate(df.dtypes.items(), 1):\n",
    "                f.write(f\"{i:2d}. {col} ({dtype})\\\\n\")\n",
    "            \n",
    "        print(f\"‚úÖ Saved summary report: {summary_file}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Summary report save failed: {e}\")\n",
    "    \n",
    "    print(f\"\\\\nüéâ Data export completed!\")\n",
    "    print(f\"üìÅ All files saved to: {os.path.abspath(output_dir)}\")\n",
    "    \n",
    "    # List all created files\n",
    "    created_files = [f for f in os.listdir(output_dir) if f.startswith(base_filename)]\n",
    "    print(f\"\\\\nüìÑ Created files:\")\n",
    "    for file in sorted(created_files):\n",
    "        file_path = os.path.join(output_dir, file)\n",
    "        file_size = os.path.getsize(file_path) / 1024**2\n",
    "        print(f\"   {file} ({file_size:.1f} MB)\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ùå No data available to save. Please load data first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39beb392",
   "metadata": {},
   "source": [
    "## Summary and Next Steps\n",
    "\n",
    "This notebook has demonstrated a complete Delta Sharing workflow using native Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b9c460",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final summary and recommendations\n",
    "print(\"üéØ Delta Sharing Python Integration - Summary\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(f\"\\n‚úÖ Successfully demonstrated:\")\n",
    "print(f\"   ‚Ä¢ Native Python Delta Sharing integration\")\n",
    "print(f\"   ‚Ä¢ Automatic handling of advanced Delta features (Deletion Vectors)\")\n",
    "print(f\"   ‚Ä¢ Direct data loading without manual file management\")\n",
    "print(f\"   ‚Ä¢ Comprehensive data exploration and analysis\")\n",
    "print(f\"   ‚Ä¢ Multiple export formats (Parquet, CSV, Excel)\")\n",
    "print(f\"   ‚Ä¢ Security best practices and authentication\")\n",
    "\n",
    "if 'df' in locals() and df is not None:\n",
    "    print(f\"\\nüìä Final dataset summary:\")\n",
    "    print(f\"   ‚Ä¢ Table: {table_name}\")\n",
    "    print(f\"   ‚Ä¢ Share: {share_name}\")  \n",
    "    print(f\"   ‚Ä¢ Schema: {schema_name}\")\n",
    "    print(f\"   ‚Ä¢ Rows: {len(df):,}\")\n",
    "    print(f\"   ‚Ä¢ Columns: {len(df.columns)}\")\n",
    "    print(f\"   ‚Ä¢ Data size: {df.memory_usage(deep=True).sum() / 1024**2:.1f} MB\")\n",
    "\n",
    "print(f\"\\nüöÄ Advantages of Python approach:\")\n",
    "print(f\"   ‚Ä¢ No R/Python integration complexity\")\n",
    "print(f\"   ‚Ä¢ Full Delta Sharing API access\")\n",
    "print(f\"   ‚Ä¢ Built-in handling of Deletion Vectors\")\n",
    "print(f\"   ‚Ä¢ Rich ecosystem (pandas, matplotlib, seaborn)\")\n",
    "print(f\"   ‚Ä¢ Easy integration with ML pipelines\")\n",
    "print(f\"   ‚Ä¢ Better error handling and debugging\")\n",
    "\n",
    "print(f\"\\nüõ†Ô∏è  Production recommendations:\")\n",
    "print(f\"   1. Use environment variables for credentials\")\n",
    "print(f\"   2. Implement automatic token refresh\")\n",
    "print(f\"   3. Add retry logic with exponential backoff\")\n",
    "print(f\"   4. Monitor token expiration\")\n",
    "print(f\"   5. Set up logging for audit trails\")\n",
    "print(f\"   6. Consider data caching strategies\")\n",
    "print(f\"   7. Implement data validation checks\")\n",
    "\n",
    "print(f\"\\nüìö Further exploration:\")\n",
    "print(f\"   ‚Ä¢ Explore incremental loading with table versions\")\n",
    "print(f\"   ‚Ä¢ Implement automated data pipelines\")\n",
    "print(f\"   ‚Ä¢ Add integration with data visualization tools\")\n",
    "print(f\"   ‚Ä¢ Set up scheduled data refreshes\")\n",
    "print(f\"   ‚Ä¢ Explore advanced filtering and predicates\")\n",
    "\n",
    "print(f\"\\nüîß Required packages for full functionality:\")\n",
    "packages = [\n",
    "    \"delta-sharing>=1.0.0\",\n",
    "    \"pandas>=1.3.0\", \n",
    "    \"matplotlib>=3.5.0\",\n",
    "    \"seaborn>=0.11.0\",\n",
    "    \"openpyxl>=3.0.0\",  # For Excel export\n",
    "    \"geopandas>=0.10.0\"  # For spatial data\n",
    "]\n",
    "\n",
    "for package in packages:\n",
    "    print(f\"   ‚Ä¢ {package}\")\n",
    "\n",
    "print(f\"\\nInstall command:\")\n",
    "print(f\"pip install {' '.join([p.split('>=')[0] for p in packages])}\")\n",
    "\n",
    "print(f\"\\n‚ú® Notebook execution completed successfully!\")\n",
    "print(f\"üìÅ Check the 'data/delta-share-downloads' folder for exported files.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "delta-sharing-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
